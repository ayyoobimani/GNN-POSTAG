{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mounts/Users/student/ayyoob/anaconda3/envs/multalign_graph/lib/python3.7/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch, sys\n",
    "sys.path.insert(0, '../')\n",
    "from my_utils import gpu_utils\n",
    "import importlib, gc\n",
    "from my_utils.alignment_features import *\n",
    "import my_utils.alignment_features as afeatures\n",
    "importlib.reload(afeatures)\n",
    "import gnn_utils.graph_utils as gutils\n",
    "import postag_utils as posutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = torch.device('cuda:4' if torch.cuda.is_available() else 'cpu')\n",
    "dev2 = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch_geometric.nn as pyg_nn\n",
    "import torch_geometric.utils as pyg_utils\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "from sklearn.manifold import TSNE\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24159\n"
     ]
    }
   ],
   "source": [
    "from my_utils import align_utils as autils, utils\n",
    "import argparse\n",
    "from multiprocessing import Pool\n",
    "import random\n",
    "\n",
    "# set random seed\n",
    "config_file = \"/mounts/Users/student/ayyoob/Dokumente/code/pbc-ui-demo/config_pbc.ini\"\n",
    "utils.setup(config_file)\n",
    "\n",
    "params = argparse.Namespace()\n",
    "\n",
    "\n",
    "params.gold_file = \"/mounts/Users/student/ayyoob/Dokumente/code/pbc_utils/data/helfi/splits/helfi-fin-grc-gold-alignments_train.txt\"\n",
    "pros, surs = autils.load_gold(params.gold_file)\n",
    "all_verses = list(pros.keys())\n",
    "params.gold_file = \"/mounts/Users/student/ayyoob/Dokumente/code/pbc_utils/data/helfi/splits/helfi-fin-heb-gold-alignments_train.txt\"\n",
    "pros, surs = autils.load_gold(params.gold_file)\n",
    "all_verses.extend(list(pros.keys()))\n",
    "all_verses = list(set(all_verses))\n",
    "print(len(all_verses))\n",
    "\n",
    "params.editions_file =  \"/mounts/Users/student/ayyoob/Dokumente/code/pbc_utils/data/helfi/splits/helfi_lang_list.txt\"\n",
    "editions, langs = autils.load_simalign_editions(params.editions_file)\n",
    "current_editions = [editions[lang] for lang in langs]\n",
    "\n",
    "def get_pruned_verse_alignments(args):\n",
    "    verse, current_editions = args\n",
    "    \n",
    "    verse_aligns_inter = autils.get_verse_alignments(verse)\n",
    "    verse_aligns_gdfa = autils.get_verse_alignments(verse, gdfa=True)\n",
    "\n",
    "    autils.prune_non_necessary_alignments(verse_aligns_inter, current_editions)\n",
    "    autils.prune_non_necessary_alignments(verse_aligns_gdfa, current_editions)\n",
    "\n",
    "    gc.collect()\n",
    "    return verse_aligns_inter, verse_aligns_gdfa\n",
    "    \n",
    "\n",
    "args = []\n",
    "for i,verse in enumerate(all_verses):\n",
    "    args.append((verse, current_editions[:]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importlib.reload(afeatures)\n",
    "\n",
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, features, n_head = 2, has_tagfreq_feature=False,):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.conv1 = pyg_nn.GATConv(in_channels, 2*out_channels, heads= n_head)\n",
    "        self.conv2 = pyg_nn.GATConv(2 * n_head *  out_channels , out_channels, heads= 1)\n",
    "        #self.fin_lin = nn.Linear(out_channels, out_channels)\n",
    "        \n",
    "        if has_tagfreq_feature:\n",
    "            self.feature_encoder = afeatures.FeatureEncoding(features, [normalized_tag_frequencies, word_vectors])\n",
    "            #self.feature_encoder = afeatures.FeatureEncoding(features, [normalized_tag_frequencies,train_pos_labels, word_vectors])\n",
    "        else:\n",
    "            self.feature_encoder = afeatures.FeatureEncoding(features, [word_vectors])\n",
    "            #self.feature_encoder = afeatures.FeatureEncoding(features, [train_pos_labels, word_vectors])\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        encoded = self.feature_encoder(x, dev)\n",
    "        x = F.elu(self.conv1(encoded, edge_index, ))\n",
    "        x = F.elu(self.conv2(x, edge_index))\n",
    "        #return F.relu(self.fin_lin(x)), encoded\n",
    "        return x, encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_encoders_embedding(encoder):\n",
    "    for i,ft in enumerate(encoder.feature_types):\n",
    "        if ft.type == MAPPING:\n",
    "            print('doing it')\n",
    "            encoder.layers[i] = afeatures.MappingEncoding(encoder.layers[i].emb.weight, freeze=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_memory():\n",
    "    gc.collect()\n",
    "    with torch.no_grad():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "class DataEncoder():\n",
    "\n",
    "    def __init__(self, data_loader, model, mask_language):\n",
    "        self.data_loader = data_loader\n",
    "        self.model = model\n",
    "        self.mask_language = mask_language\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for i,batch in enumerate(tqdm(self.data_loader)):\n",
    "            try:\n",
    "                optimizer.zero_grad()\n",
    "            except NameError:\n",
    "                # it is ok since if we call test before train, optimizer is not defined\n",
    "                pass\n",
    "\n",
    "            x = batch['x'][0].to(dev)  # initial features (not encoded)\n",
    "            edge_index = batch['edge_index'][0].to(dev) \n",
    "            verse = batch['verse'][0]\n",
    "\n",
    "            if verse in masked_verses:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                if self.mask_language:\n",
    "                    x[:, 0] = 0\n",
    "                z, encoded = self.model.encode(x, edge_index) # Z will be the output of the GNN\n",
    "                batch['encoded'] = encoded\n",
    "            except Exception as e:\n",
    "                global sag, khar, gav\n",
    "                sag, khar, gav =  (i, batch, verse)\n",
    "                print(e)\n",
    "                1/0\n",
    "            \n",
    "            yield z, verse, i, batch\n",
    "\n",
    "def train(epoch, data_loader, mask_language, test_data_loader, max_batches=999999999):\n",
    "    global optimizer\n",
    "    total_loss = 0\n",
    "    model.train()\n",
    "    loss_multi_round = 0\n",
    "\n",
    "    data_encoder = DataEncoder(data_loader, model, mask_language)\n",
    "\n",
    "    for z, verse, i, batch in data_encoder:\n",
    "        \n",
    "        target = batch['pos_classes'][0].to(dev)\n",
    "        _, labels = torch.max(target, 1)\n",
    "        \n",
    "        index = batch['pos_index'][0].to(dev)\n",
    "\n",
    "        preds = model.decoder(z, index, batch)\n",
    "\n",
    "        # print(preds.shape, labels.shape)\n",
    "        loss = criterion(preds, labels)\n",
    "        loss = loss * target.shape[0] # TODO check if this is necessary\n",
    "        loss.backward()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        if (i+1) % 1 == 0: # Gradient accumulation\n",
    "            optimizer.step()\n",
    "            \n",
    "\n",
    "        if i % 500 == 499:\n",
    "            print(f\"loss: {total_loss}\")\n",
    "            total_loss = 0\n",
    "            test(epoch, test_data_loader, mask_language)\n",
    "            model.train()\n",
    "            clean_memory()\n",
    "\n",
    "        if i == max_batches:\n",
    "            break\n",
    "    \n",
    "    print(f\"total train loss: {total_loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class POSDecoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_class, drop_out=0):\n",
    "        super(POSDecoder, self).__init__()\n",
    "\n",
    "        self.transfer = nn.Sequential(nn.Linear(input_size, hidden_size), nn.ReLU(), nn.Dropout(drop_out),\n",
    "                        nn.Linear(hidden_size, hidden_size), nn.ReLU(), nn.Dropout(drop_out),\n",
    "                        nn.Linear(hidden_size, n_class))\n",
    "\n",
    "    def forward(self, z, index, batch=None):\n",
    "        h = z[index, :]\n",
    "\n",
    "        res = self.transfer(h)\n",
    "\n",
    "        return res\n",
    "\n",
    "class POSDecoderTransformer(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_class, drop_out=0):\n",
    "        super(POSDecoderTransformer, self).__init__()\n",
    "\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=input_size, nhead=8, dim_feedforward=hidden_size)\n",
    "        self.transformer = nn.TransformerEncoder(self.encoder_layer, num_layers=6)\n",
    "\n",
    "        self.transfer = nn.Sequential( nn.Linear(input_size, hidden_size), nn.ReLU(), nn.Dropout(drop_out), # TODO check what happens if I remove this.\n",
    "                        nn.Linear(hidden_size, n_class))\n",
    "\n",
    "    def forward(self, z_, index, batch_):\n",
    "        z = z_.to(dev2)\n",
    "\n",
    "        x = F.pad(batch_['encoded'], (0, z.size(1) - batch_['encoded'].size(1))).to(dev2)\n",
    "\n",
    "\n",
    "        language_based_nodes = batch_['lang_based_nodes'] # determines which node belongs to which language\n",
    "        transformer_indices = batch_['transformer_indices'] # the reverse of the prev structure\n",
    "\n",
    "        sentences = []\n",
    "        for lang_nodes in language_based_nodes: # we rearrange the nodes into sentences of each language\n",
    "            tensor = z[lang_nodes, :] + x[lang_nodes, :]\n",
    "            tensor = F.pad(tensor, (0, 0, 0, 150 - tensor.size(0)))\n",
    "            sentences.append(tensor)\n",
    "        \n",
    "        batch = torch.stack(sentences) # A batch contains all translations of one sentence in all training languages.\n",
    "        batch = torch.transpose(batch, 0, 1)\n",
    "\n",
    "        h = self.transformer(batch)\n",
    "        h = torch.transpose(h, 0, 1)\n",
    "        h = h[transformer_indices[0], transformer_indices[1], :] # rearrange the nodes back to the order in which we recieved (the order that represents the graph)\n",
    "\n",
    "        res = self.transfer(h)\n",
    "\n",
    "        return res.to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch, testloader, mask_language, filter_wordtypes=None):\n",
    "    print('testing',  epoch)\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "\n",
    "    data_encoder = DataEncoder(testloader, model, mask_language)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for z, verse, i, batch in data_encoder:\n",
    "            \n",
    "            target = batch['pos_classes'][0].to(dev)\n",
    "            index = batch['pos_index'][0].to(dev)\n",
    "            \n",
    "            if filter_wordtypes != None:\n",
    "                non_filtered_words = filter_wordtypes[batch['x'][0][:, 9].long()] == 1\n",
    "                non_filtered_words = non_filtered_words[index]\n",
    "                index = index[non_filtered_words]\n",
    "\n",
    "                target = target[non_filtered_words, :]\n",
    "\n",
    "            preds = model.decoder(z, index, batch)\n",
    "            \n",
    "            if preds.size(0) > 0:\n",
    "                _, predicted = torch.max(preds, 1)\n",
    "                _, labels = torch.max(target, 1)\n",
    "\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print(f'test, epoch: {epoch}, total:{total} ACC: {correct/total}')\n",
    "    clean_memory()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority_voting_test(data_loader1, data_loader2):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    \n",
    "    for i,(batch, batch2) in enumerate(tqdm(zip(data_loader1, data_loader2))) :\n",
    "            \n",
    "        x = batch['x'][0]\n",
    "        edge_index = batch['edge_index'][0]\n",
    "        verse = batch['verse'][0]\n",
    "\n",
    "        if verse in masked_verses:\n",
    "            continue\n",
    "\n",
    "        target = batch['pos_classes'][0]\n",
    "        index = batch['pos_index'][0]\n",
    "\n",
    "        index2 = batch2['pos_index'][0]\n",
    "        \n",
    "\n",
    "        for node, label in zip(index,target):\n",
    "            other_side = edge_index[1, edge_index[0, :] == node]\n",
    "            other_side_withpos = other_side[[True if i in index2 else False for i in other_side]]\n",
    "            other_side_target_indices = [(i == index2).nonzero(as_tuple=True)[0].item() for i in other_side_withpos]\n",
    "            #print(other_side_target_indices)\n",
    "            proj_tags = batch2['pos_classes'][0][other_side_target_indices]\n",
    "\n",
    "            if proj_tags.size(0) > 0:\n",
    "                _, proj_tags = torch.max(proj_tags, 1)\n",
    "                #print(target.shape, node, index.shape, proj_tags, other_side)\n",
    "                \n",
    "                if torch.argmax(label) == torch.mode(proj_tags)[0]:\n",
    "                    correct += 1\n",
    "                \n",
    "                total += 1\n",
    "\n",
    "    print(f'test, , total:{total} ACC: {correct/total}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(wordtype_frequencies[736])\n",
    "#print(wordtype_frequencies[1473])\n",
    "#print(wordtype_frequencies[3683])\n",
    "#print(wordtype_frequencies[7367])\n",
    "#print(wordtype_frequencies[14733])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#frequent_words = torch.zeros(word_frequencies.size(0))\n",
    "#frequent_words[word_frequencies > -1] = 1\n",
    "\n",
    "#test(1, test_data_loader, filter_wordtypes=frequent_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2354770, 100)\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "w2v_model = Word2Vec.load(\"/mounts/work/ayyoob/models/w2v/word2vec_helfi_langs_15e.model\")\n",
    "\n",
    "print(w2v_model.wv.vectors.shape)\n",
    "word_vectors = torch.from_numpy(w2v_model.wv.vectors).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "train_verses = all_verses[:]\n",
    "test_verses = all_verses[:] \n",
    "editf1 = 'fin-x-bible-helfi'\n",
    "editf2 = \"heb-x-bible-helfi\"\n",
    "\n",
    "\n",
    "if 'jpn-x-bible-newworld' in  current_editions[:]:\n",
    "     current_editions.remove('jpn-x-bible-newworld')\n",
    "if 'grc-x-bible-unaccented' in  current_editions[:]:\n",
    "     current_editions.remove('grc-x-bible-unaccented')\n",
    "\n",
    "\n",
    "\n",
    "data_dir_train = \"/mounts/data/proj/ayyoob/align_induction/dataset/dataset_helfi_train_community_word\"\n",
    "data_dir_blinker = \"/mounts/data/proj/ayyoob/align_induction/dataset/pruned_alignments_blinker_inter/\"\n",
    "data_dir_grc = \"/mounts/data/proj/ayyoob/align_induction/dataset/dataset_helfi_grc_community_word/\"\n",
    "data_dir_heb = \"/mounts/data/proj/ayyoob/align_induction/dataset/dataset_helfi_heb_community_word/\"\n",
    "\n",
    "train_dataset = torch.load(f\"{data_dir_train}/train_dataset_nox_noedge.torch.bin\")\n",
    "blinker_test_dataset = torch.load(f\"{data_dir_blinker}/train_dataset_nox_noedge.torch.bin\")\n",
    "grc_test_dataset = torch.load(f\"{data_dir_grc}/train_dataset_nox_noedge.torch.bin\")\n",
    "heb_test_dataset = torch.load(f\"{data_dir_heb}/train_dataset_nox_noedge.torch.bin\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import collections\n",
    "\n",
    "postag_map = {\"ADJ\": 0, \"ADP\": 1, \"ADV\": 2, \"AUX\": 3, \"CCONJ\": 4, \"DET\": 5, \"INTJ\": 6, \"NOUN\": 7, \"NUM\": 8, \"PART\": 9, \"PRON\": 10, \"PROPN\": 11, \"PUNCT\": 12, \"SCONJ\": 13, \"SYM\": 14, \"VERB\": 15, \"X\": 16}\n",
    "\n",
    "pos_lang_list = [\"eng-x-bible-mixed\", \"deu-x-bible-newworld\", \"ces-x-bible-newworld\", \n",
    "\t\t\"fra-x-bible-louissegond\",\"hin-x-bible-newworld\", \"ita-x-bible-2009\", \n",
    "\t\t\"prs-x-bible-goodnews\", \"ron-x-bible-2006\", \"spa-x-bible-newworld\"]\n",
    "\n",
    "def get_db_nodecount(dataset):\n",
    "\tres = 0\n",
    "\tfor lang in dataset.nodes_map.values():\n",
    "\t\tfor verse in lang.values():\n",
    "\t\t\tres += len(verse)\n",
    "\t\n",
    "\treturn res\n",
    "\n",
    "def get_language_nodes(dataset, lang_list, sentences):\n",
    "\tnode_count = get_db_nodecount(dataset)\n",
    "\tpos_labels = torch.zeros(node_count, len(postag_map))\n",
    "\n",
    "\tpos_node_cover = collections.defaultdict(list)\n",
    "\tfor lang in lang_list:\n",
    "\t\tfor sentence in sentences:\n",
    "\t\t\tif sentence in dataset.nodes_map[lang]:\n",
    "\t\t\t\tfor tok in dataset.nodes_map[lang][sentence]:\n",
    "\t\t\t\t\tpos_node_cover[sentence].append(dataset.nodes_map[lang][sentence][tok])\n",
    "\t\n",
    "\treturn pos_labels, pos_node_cover\n",
    "\n",
    "\n",
    "def get_pos_tags(dataset, pos_lang_list):\n",
    "\tall_tags = {}\n",
    "\tfor lang in pos_lang_list:\n",
    "\t\tif lang not in dataset.nodes_map:\n",
    "\t\t\tcontinue\n",
    "\t\tall_tags[lang] = {}\n",
    "\t\twith codecs.open(F\"/mounts/work/mjalili/projects/gnn-align/data/pbc_pos_tags/{lang}.conllu\", \"r\", \"utf-8\") as lang_pos:\n",
    "\t\t\ttag_sent = []\n",
    "\t\t\tsent_id = \"\"\n",
    "\t\t\tfor sline in lang_pos:\n",
    "\t\t\t\tsline = sline.strip()\n",
    "\t\t\t\tif sline == \"\":\n",
    "\t\t\t\t\tif sent_id not in dataset.nodes_map[lang]:\n",
    "\t\t\t\t\t\ttag_sent = []\n",
    "\t\t\t\t\t\tsent_id = \"\"\n",
    "\t\t\t\t\t\tcontinue\n",
    "\n",
    "\t\t\t\t\tall_tags[lang][sent_id] = [p[3] for p in tag_sent]\n",
    "\t\t\t\t\ttag_sent = []\n",
    "\t\t\t\t\tsent_id = \"\"\n",
    "\t\t\t\telif \"# verse_id\" in sline:\n",
    "\t\t\t\t\tsent_id = sline.split()[-1]\n",
    "\t\t\t\telif sline[0] == \"#\":\n",
    "\t\t\t\t\tcontinue\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\ttag_sent.append(sline.split(\"\\t\"))\n",
    "\n",
    "\tnode_count = get_db_nodecount(dataset)\n",
    "\tpos_labels = torch.zeros(node_count, len(postag_map))\n",
    "\tpos_node_cover = collections.defaultdict(list)\n",
    "\n",
    "\tfor lang in all_tags:\n",
    "\t\tfor sent_id in all_tags[lang]:\n",
    "\t\t\tsent_tags = all_tags[lang][sent_id]\n",
    "\t\t\tfor w_i in range(len(sent_tags)):\n",
    "\t\t\t\tif w_i not in dataset.nodes_map[lang][sent_id]:\n",
    "\t\t\t\t\tcontinue\n",
    "\t\t\t\tpos_labels[dataset.nodes_map[lang][sent_id][w_i], postag_map[sent_tags[w_i]]] = 1\n",
    "\t\t\t\tpos_node_cover[sent_id].append(dataset.nodes_map[lang][sent_id][w_i])\n",
    "\n",
    "\treturn pos_labels, pos_node_cover\n",
    "\t#pos_pickle = {\"pos_labels\": pos_labels, \"node_ids_train\": pos_ids_train, \"node_ids_dev\": pos_ids_dev}\n",
    "\t#torch.save(pos_pickle, '/mounts/work/ayyoob/models/gnn/postag')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# blinker_test_dataset = torch.load(\"/mounts/work/ayyoob/models/gnn/dataset_blinker_full_community_word.pickle\", map_location=torch.device('cpu'))\n",
    "editf12 = \"eng-x-bible-mixed\"\n",
    "editf22 = 'fra-x-bible-louissegond'\n",
    "\n",
    "test_gold_eng_fra = \"/mounts/Users/student/ayyoob/Dokumente/code/pbc_utils/data/eng_fra_pbc/eng-fra.gold\"\n",
    "\n",
    "pros_blinker, surs_blinker = autils.load_gold(test_gold_eng_fra)\n",
    "\n",
    "blinker_verse_alignments_inter = {}\n",
    "\n",
    "verses_map = {}\n",
    "\n",
    "for edit in blinker_test_dataset.nodes_map:\n",
    "    for verse in blinker_test_dataset.nodes_map[edit]:\n",
    "        if verse not in verses_map:\n",
    "            for tok in blinker_test_dataset.nodes_map[edit][verse]:\n",
    "                verses_map[verse] = blinker_test_dataset.nodes_map[edit][verse][tok]\n",
    "                break\n",
    "\n",
    "sorted_verses = sorted(verses_map.items(), key = lambda x: x[1])\n",
    "blinker_verses = [item[0] for item in sorted_verses]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importlib.reload(afeatures)\n",
    "#grc_test_dataset = torch.load(\"/mounts/work/ayyoob/models/gnn/dataset_helfi_grc_test_community_word.pickle\", map_location=torch.device('cpu'))\n",
    "editf_fin = \"fin-x-bible-helfi\"\n",
    "editf_grc = 'grc-x-bible-helfi'\n",
    "\n",
    "test_gold_grc = \"/mounts/Users/student/ayyoob/Dokumente/code/pbc_utils/data/helfi/splits/helfi-fin-grc-gold-alignments_test.txt\"\n",
    "\n",
    "pros_grc, surs_grc = autils.load_gold(test_gold_grc)\n",
    "\n",
    "grc_test_verse_alignments_inter = {}\n",
    "grc_test_verse_alignments_gdfa = {}\n",
    "gc.collect()\n",
    "\n",
    "verses_map = {}\n",
    "\n",
    "for edit in grc_test_dataset.nodes_map:\n",
    "    for verse in grc_test_dataset.nodes_map[edit]:\n",
    "        if verse not in verses_map:\n",
    "            for tok in grc_test_dataset.nodes_map[edit][verse]:\n",
    "                verses_map[verse] = grc_test_dataset.nodes_map[edit][verse][tok]\n",
    "                break\n",
    "\n",
    "sorted_verses = sorted(verses_map.items(), key = lambda x: x[1])\n",
    "grc_test_verses = [item[0] for item in sorted_verses]\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#heb_test_dataset = torch.load(\"/mounts/work/ayyoob/models/gnn/dataset_helfi_heb_test_community_word.pickle\", map_location=torch.device('cpu'))\n",
    "\n",
    "test_gold_heb = \"/mounts/Users/student/ayyoob/Dokumente/code/pbc_utils/data/helfi/splits/helfi-fin-heb-gold-alignments_test.txt\"\n",
    "\n",
    "pros_heb, surs_heb = autils.load_gold(test_gold_heb)\n",
    "\n",
    "verses_map = {}\n",
    "\n",
    "for edit in heb_test_dataset.nodes_map:\n",
    "    for verse in heb_test_dataset.nodes_map[edit]:\n",
    "        if verse not in verses_map:\n",
    "            for tok in heb_test_dataset.nodes_map[edit][verse]:\n",
    "                verses_map[verse] = heb_test_dataset.nodes_map[edit][verse][tok]\n",
    "                break\n",
    "\n",
    "sorted_verses = sorted(verses_map.items(), key = lambda x: x[1])\n",
    "heb_test_verses = [item[0] for item in sorted_verses]\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "verses_map = {}\n",
    "\n",
    "for edit in train_dataset.nodes_map:\n",
    "    for verse in train_dataset.nodes_map[edit]:\n",
    "        if verse not in verses_map:\n",
    "            for tok in train_dataset.nodes_map[edit][verse]:\n",
    "                verses_map[verse] = train_dataset.nodes_map[edit][verse][tok]\n",
    "                break\n",
    "\n",
    "sorted_verses = sorted(verses_map.items(), key = lambda x: x[1])\n",
    "all_verses = [item[0] for item in sorted_verses]\n",
    "\n",
    "long_verses = set()\n",
    "\n",
    "for edit in train_dataset.nodes_map.keys():\n",
    "    for verse in train_dataset.nodes_map[edit]:\n",
    "        to_print = False\n",
    "        for tok in train_dataset.nodes_map[edit][verse]:\n",
    "            if tok > 150:\n",
    "                to_print = True\n",
    "        if to_print == True:\n",
    "            long_verses.add(verse)\n",
    "\n",
    "\n",
    "train_verses = all_verses[:]\n",
    "\n",
    "masked_verses = list(long_verses)\n",
    "#masked_verses.extend(blinker_verses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "\n",
    "def get_language_based_nodes(nodes_map, verse, train_nodes, padding):\n",
    "    res = []\n",
    "    transformer_indices = [[-1 for i in range(len(train_nodes))],[-1 for i in range(len(train_nodes))]]\n",
    "    \n",
    "    lang_ind = 0\n",
    "    for lang in nodes_map:\n",
    "        if verse in nodes_map[lang]:\n",
    "            items = nodes_map[lang][verse].items()\n",
    "            items = sorted(items, key=lambda i: i[0])\n",
    "\n",
    "            to_add = []\n",
    "            for i, it in enumerate(items):\n",
    "                to_add.append(it[1] - padding)\n",
    "                if it[1] in train_nodes:\n",
    "                    index = train_nodes.index(it[1])\n",
    "                    transformer_indices[0][index] = lang_ind\n",
    "                    transformer_indices[1][index] = i\n",
    "\n",
    "            res.append(to_add)\n",
    "            lang_ind += 1\n",
    "            \n",
    "    return res, transformer_indices\n",
    "\n",
    "class POSTAGGNNDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataset, verses, edit_files, alignments, node_cover, pos_labels, data_dir, create_data=False, group_size = 20):\n",
    "        self.node_cover = node_cover\n",
    "        self.pos_labels = pos_labels\n",
    "        self.data_dir = data_dir\n",
    "        self.items = self.calculate_size(verses, group_size, node_cover)\n",
    "        self.dataset = dataset\n",
    "\n",
    "        if create_data:\n",
    "            self.calculate_verse_stats(verses, edit_files, alignments, dataset, data_dir)            \n",
    "        \n",
    "    def calculate_size(self, verses, group_size, node_cover):\n",
    "        res = []\n",
    "        for verse in verses:\n",
    "            covered_nodes = node_cover[verse]\n",
    "            random.shuffle(covered_nodes)\n",
    "            items = [covered_nodes[i:i + group_size] for i in range(0, len(covered_nodes), group_size)]\n",
    "            res.extend([(verse, i) for i in items])\n",
    "\n",
    "        return res\n",
    "\n",
    "    def calculate_verse_stats(self,verses, edition_files, alignments, dataset, data_dir):\n",
    "\n",
    "        min_edge = 0\n",
    "        for verse in tqdm(verses):\n",
    "            min_nodes = 99999999999999\n",
    "            max_nodes = 0\n",
    "            edges_tmp = [[],[]]\n",
    "            x_tmp = []\n",
    "            features = []\n",
    "            for i,editf1 in enumerate(edition_files):\n",
    "                for j,editf2 in enumerate(edition_files[i+1:]):\n",
    "                    aligns = autils.get_aligns(editf1, editf2, alignments[verse])\n",
    "                    if aligns != None:\n",
    "                        for align in aligns:\n",
    "                            try:\n",
    "                                n1,_ = gutils.node_nom(verse, editf1, align[0], None, dataset.nodes_map, x_tmp, edition_files, features)\n",
    "                                n2,_ = gutils.node_nom(verse, editf2, align[1], None, dataset.nodes_map, x_tmp, edition_files, features)\n",
    "                                edges_tmp[0].extend([n1, n2])\n",
    "\n",
    "                                max_nodes = max(n1, n2, max_nodes)\n",
    "                                min_nodes = min(n1, n2, min_nodes)\n",
    "                            except Exception as e:\n",
    "                                print(editf1, editf2, verse)\n",
    "                                raise(e)\n",
    "\n",
    "            self.verse_info = {}\n",
    "\n",
    "            self.verse_info['padding'] = min_nodes\n",
    "            \n",
    "            self.verse_info['x'] = torch.clone(dataset.x[min_nodes:max_nodes+1,:])\n",
    "            \n",
    "            self.verse_info['edge_index'] = torch.clone(dataset.edge_index[:, min_edge : min_edge + len(edges_tmp[0])] - min_nodes)\n",
    "\n",
    "            if torch.min(self.verse_info['edge_index']) != 0:\n",
    "                print(verse, min_nodes, max_nodes, min_edge, len(edges_tmp[0]))\n",
    "                print(torch.min(self.verse_info['edge_index']))\n",
    "            \n",
    "            if self.verse_info['x'].shape[0] != torch.max(self.verse_info['edge_index']) + 1 :\n",
    "                print(verse, min_nodes, max_nodes, min_edge, len(edges_tmp[0]))\n",
    "                print(torch.min(self.verse_info['edge_index']))\n",
    "            \n",
    "            min_edge = min_edge + len(edges_tmp[0])\n",
    "\n",
    "            torch.save(self.verse_info, f\"{data_dir}/verses/{verse}_info.torch.bin\")\n",
    "        \n",
    "        dataset.x = None\n",
    "        dataset.edge_index = None\n",
    "        torch.save(dataset, f\"{data_dir}/train_dataset_nox_noedge.torch.bin\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.items)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        verse, nodes = self.items[idx]\n",
    "        \n",
    "        self.verse_info = {verse: torch.load(f'{self.data_dir}/verses/{verse}_info.torch.bin')}\n",
    "\n",
    "\n",
    "        word_number = self.verse_info[verse]['x'][:, 9]\n",
    "        padding = self.verse_info[verse]['padding']\n",
    "        \n",
    "        language_based_nodes, transformer_indices = get_language_based_nodes(self.dataset.nodes_map, verse, nodes, padding)\n",
    "\n",
    "        ## # Add POSTAG to set of features\n",
    "        #postags = self.pos_labels[padding: self.verse_info[verse]['x'].size(0) + padding, : ]\n",
    "        #postags = postags.detach().clone()\n",
    "        #postags[torch.LongTensor(nodes) - padding, :] = 0\n",
    "        #self.verse_info[verse]['x'] = torch.cat((self.verse_info[verse]['x'], postags), dim=1)\n",
    "\n",
    "        # Add token id as a feature, used to extract token information (like token's tag distribution)\n",
    "        word_number = torch.unsqueeze(word_number, 1)\n",
    "        self.verse_info[verse]['x'] = torch.cat((self.verse_info[verse]['x'], word_number), dim=1)\n",
    "\n",
    "        return {'verse':verse, 'x':self.verse_info[verse]['x'], 'edge_index':self.verse_info[verse]['edge_index'], \n",
    "                'pos_classes': self.pos_labels[nodes, :], 'pos_index': torch.LongTensor(nodes) - padding, \n",
    "                'padding': padding, 'lang_based_nodes': language_based_nodes, 'transformer_indices': transformer_indices}\n",
    "\n",
    "def create_me_a_gnn_dataset_you_stupid(node_covers, labels, group_size=100, editions=current_editions):\n",
    "\n",
    "    train_ds = POSTAGGNNDataset(train_dataset, train_verses, editions, {}, node_covers[0], labels[0], data_dir_train, group_size=group_size)\n",
    "    grc_ds = POSTAGGNNDataset(grc_test_dataset, grc_test_verses, editions, {}, node_covers[1], labels[1], data_dir_grc, group_size=group_size)\n",
    "    heb_ds = POSTAGGNNDataset(heb_test_dataset, heb_test_verses, editions, {}, node_covers[2], labels[2], data_dir_heb, group_size=group_size)\n",
    "    blinker_ds = POSTAGGNNDataset(blinker_test_dataset, blinker_verses, editions, {}, node_covers[3], labels[3], data_dir_blinker, group_size=group_size)\n",
    "\n",
    "    return train_ds, grc_ds, heb_ds, blinker_ds\n",
    "\n",
    "#train_pos_labels, train_pos_node_cover = get_pos_tags(train_dataset, pos_lang_list)\n",
    "#torch.save({'pos_labels':train_pos_labels, 'pos_node_cover':train_pos_node_cover}, f'{data_dir_train}/pos_data.torch.bin')\n",
    "pos_data = torch.load(f'{data_dir_train}/pos_data.torch.bin')\n",
    "train_pos_labels, train_pos_node_cover = pos_data['pos_labels'], pos_data['pos_node_cover']\n",
    "\n",
    "##blinker_pos_labels, blinker_pos_node_cover = get_pos_tags(blinker_test_dataset, pos_lang_list)\n",
    "##torch.save({'pos_labels':blinker_pos_labels, 'pos_node_cover': blinker_pos_node_cover}, f'{data_dir_blinker}/pos_data.torch.bin')\n",
    "pos_data = torch.load(f'{data_dir_blinker}/pos_data.torch.bin')\n",
    "blinker_pos_labels, blinker_pos_node_cover = pos_data['pos_labels'], pos_data['pos_node_cover']\n",
    "\n",
    "grc_pos_labels, grc_pos_node_cover = get_pos_tags(grc_test_dataset, pos_lang_list)\n",
    "torch.save({'pos_labels':grc_pos_labels, 'pos_node_cover': grc_pos_node_cover}, f'{data_dir_grc}/pos_data.torch.bin')\n",
    "#pos_data = torch.load(f'{data_dir_grc}/pos_data.torch.bin')\n",
    "#grc_pos_labels, grc_pos_node_cover = pos_data['pos_labels'], pos_data['pos_node_cover']\n",
    "\n",
    "heb_pos_labels, heb_pos_node_cover = get_pos_tags(heb_test_dataset, pos_lang_list)\n",
    "torch.save({'pos_labels':heb_pos_labels, 'pos_node_cover': heb_pos_node_cover}, f'{data_dir_heb}/pos_data.torch.bin')\n",
    "#pos_data = torch.load(f'{data_dir_heb}/pos_data.torch.bin')\n",
    "#heb_pos_labels, heb_pos_node_cover = pos_data['pos_labels'], pos_data['pos_node_cover']\n",
    "\n",
    "gnn_dataset_train_pos, gnn_dataset_grc_pos, gnn_dataset_heb_pos, gnn_dataset_blinker_pos = create_me_a_gnn_dataset_you_stupid(\n",
    "    [train_pos_node_cover, grc_pos_node_cover, heb_pos_node_cover, blinker_pos_node_cover], [train_pos_labels, grc_pos_labels, heb_pos_labels, blinker_pos_labels], group_size=100)\n",
    "\n",
    "gnn_dataset_train_pos_bigbatch, gnn_dataset_grc_pos_bigbatch, gnn_dataset_heb_pos_bigbatch, gnn_dataset_blinker_pos_bigbatch = create_me_a_gnn_dataset_you_stupid(\n",
    "    [train_pos_node_cover, grc_pos_node_cover, heb_pos_node_cover, blinker_pos_node_cover], [train_pos_labels, grc_pos_labels, heb_pos_labels, blinker_pos_labels], group_size=10000)\n",
    "\n",
    "train_data_loader_bigbatch = DataLoader(gnn_dataset_train_pos_bigbatch, batch_size=1, shuffle=False)\n",
    "grc_data_loader_bigbatch = DataLoader(gnn_dataset_grc_pos_bigbatch, batch_size=1, shuffle=False)\n",
    "heb_data_loader_bigbatch = DataLoader(gnn_dataset_heb_pos_bigbatch, batch_size=1, shuffle=False)\n",
    "blinker_data_loader_bigbatch = DataLoader(gnn_dataset_blinker_pos_bigbatch, batch_size=1, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no_eng_langs = pos_lang_list[:]\n",
    "#no_eng_langs.remove('eng-x-bible-mixed')\n",
    "\n",
    "## # train_pos_labels, train_pos_node_cover = get_pos_tags(train_dataset, no_eng_langs)\n",
    "## # gnn_dataset_train_pos = POSTAGGNNDataset(train_dataset, train_verses, current_editions, verse_alignments_inter,\n",
    "## #                        train_pos_node_cover, train_pos_labels, data_dir_train, group_size = 10)\n",
    "\n",
    "\n",
    "#_, blinker_pos_node_cover = get_pos_tags(blinker_test_dataset, ['eng-x-bible-mixed'])\n",
    "#blinker_pos_labels, _ = get_pos_tags(blinker_test_dataset, pos_lang_list)\n",
    "#gnn_dataset_blinker_pos_onlyeng = POSTAGGNNDataset(blinker_test_dataset, blinker_verses, current_editions, blinker_verse_alignments_inter,\n",
    "#                            blinker_pos_node_cover, blinker_pos_labels, data_dir_blinker, group_size = 500)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, name):\n",
    "    #model.encoder.feature_encoder.feature_types[0] = afeatures.OneHotFeature(20, 83, 'editf')\n",
    "    #model.encoder.feature_encoder.feature_types[1] = afeatures.OneHotFeature(32, 150, 'position')\n",
    "    #model.encoder.feature_encoder.feature_types[2] = afeatures.FloatFeature(4, 'degree_centrality')\n",
    "    #model.encoder.feature_encoder.feature_types[3] = afeatures.FloatFeature(4, 'closeness_centrality')\n",
    "    #model.encoder.feature_encoder.feature_types[4] = afeatures.FloatFeature(4, 'betweenness_centrality')\n",
    "    #model.encoder.feature_encoder.feature_types[5] = afeatures.FloatFeature(4, 'load_centrality')\n",
    "    #model.encoder.feature_encoder.feature_types[6] = afeatures.FloatFeature(4, 'harmonic_centrality')\n",
    "    #model.encoder.feature_encoder.feature_types[7] = afeatures.OneHotFeature(32, 250, 'greedy_modularity_community')\n",
    "    #model.encoder.feature_encoder.feature_types[8] = afeatures.OneHotFeature(32, 250, 'community_2')\n",
    "    #model.encoder.feature_encoder.feature_types[9] = afeatures.MappingFeature(100, 'word')\n",
    "    #model.encoder.feature_encoder.feature_types[10] = afeatures.MappingFeature(len(postag_map), 'tag_priors', freeze=True)\n",
    "    torch.save(model, f'/mounts/work/ayyoob/models/gnn/checkpoint/postagging/pos_tagging_{name}_' + datetime.now().strftime(\"%Y%m%d-%H%M%S\") + '.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_test_pos_labels, eng_test_pos_node_cover = get_pos_tags(blinker_test_dataset, ['eng-x-bible-mixed'])\n",
    "gnn_dataset_engtest_pos = POSTAGGNNDataset(blinker_test_dataset, blinker_verses, current_editions, {},\n",
    "                      eng_test_pos_node_cover, eng_test_pos_labels, data_dir_blinker, group_size = 500)\n",
    "engtest_data_loader = DataLoader(gnn_dataset_engtest_pos, batch_size=1, shuffle=False)\n",
    "\n",
    "#test(1, engtest_data_loader, mask_language=False) \n",
    "\n",
    "finetune_pos_labels, finetune_pos_node_cover = get_pos_tags(train_dataset, ['eng-x-bible-mixed'])\n",
    "gnn_dataset_finetune_pos = POSTAGGNNDataset(train_dataset, train_verses, current_editions, {},\n",
    "                      finetune_pos_node_cover, finetune_pos_labels, data_dir_train, group_size = 100)\n",
    "finetune_data_loader = DataLoader(gnn_dataset_finetune_pos, batch_size=1, shuffle=False)\n",
    "\n",
    "\n",
    "#train(1, finetune_data_loader, mask_language=False)\n",
    "#test(1, engtest_data_loader, mask_language=False) \n",
    "\n",
    "# blinker_pos_labels, blinker_pos_node_cover = get_pos_tags(blinker_test_dataset, ['eng-x-bible-mixed'])\n",
    "# gnn_dataset_blinker_pos = POSTAGGNNDataset(blinker_test_dataset, blinker_verses, current_editions, blinker_verse_alignments_inter,\n",
    "#                              blinker_pos_node_cover, blinker_pos_labels, data_dir_blinker, group_size = 10000)\n",
    "\n",
    "# blinker_pos_labels, blinker_pos_node_cover = get_pos_tags(blinker_test_dataset, no_eng_langs)\n",
    "# gnn_dataset_blinker_pos_majvoting_test = POSTAGGNNDataset(blinker_test_dataset, blinker_verses, current_editions, blinker_verse_alignments_inter,\n",
    "#                              blinker_pos_node_cover, blinker_pos_labels, data_dir_blinker, group_size = 10000)\n",
    "\n",
    "# test_data_loader = DataLoader(gnn_dataset_blinker_pos, batch_size=1, shuffle=False)\n",
    "# test_data_loader_majvoting = DataLoader(gnn_dataset_blinker_pos_majvoting_test, batch_size=1, shuffle=False)\n",
    "# majority_voting_test(test_data_loader, test_data_loader_majvoting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importlib.reload(posutil)\n",
    "#target_data_loader_train = get_data_loadrs_for_target_editions(['yor-x-bible-2010'], train_dataset, train_pos_node_cover, train_verses, data_dir_train)\n",
    "#target_data_loader_grc = get_data_loadrs_for_target_editions(['yor-x-bible-2010'], grc_test_dataset, grc_pos_node_cover, grc_test_verses, data_dir_grc)\n",
    "#target_data_loader_heb = get_data_loadrs_for_target_editions(['yor-x-bible-2010'], heb_test_dataset, heb_pos_node_cover, heb_test_verses, data_dir_heb)\n",
    "#target_data_loader_blinker = get_data_loadrs_for_target_editions(['yor-x-bible-2010'], blinker_test_dataset, blinker_pos_node_cover, blinker_verses, data_dir_blinker)\n",
    "\n",
    "#res_ = posutil.get_tag_frequencies_node_tags(model, ['yor-x-bible-2010'], train_pos_node_cover, train_pos_labels, grc_pos_node_cover, grc_pos_labels, heb_pos_node_cover, heb_pos_labels, blinker_pos_node_cover, blinker_pos_labels,\n",
    "#                                    len(postag_map), target_data_loader_train, target_data_loader_grc, target_data_loader_heb, target_data_loader_blinker,\n",
    "#                                    train_data_loader_bigbatch, grc_data_loader_bigbatch, heb_data_loader_bigbatch, blinker_data_loader_bigbatch, DataEncoder)\n",
    "##torch.save(res_, f'/mounts/work/ayyoob/results/gnn_postag/data/feature_vectors_posfea{True}_targetyor.torch.bin')\n",
    "##res_ = torch.load('/mounts/work/ayyoob/results/gnn_postag/data/feature_vectors_posfeaTrue_targetyor.torch.bin')\n",
    "#tag_frequencies, tag_frequencies_target, train_pos_node_cover_ext, train_pos_labels_ext, grc_pos_node_cover_ext, grc_pos_labels_ext, heb_pos_node_cover_ext, heb_pos_labels_ext, blinker_pos_node_cover_ext, blinker_pos_labels_ext = res_\n",
    "\n",
    "\n",
    "#word_frequencies_target = torch.sum(tag_frequencies_target, dim=1)\n",
    "#tag_frequencies_copy = tag_frequencies.detach().clone()\n",
    "\n",
    "#tag_frequencies_copy[torch.logical_and(word_frequencies_target>0.1, word_frequencies_target<3), :] = 0.0000001\n",
    "\n",
    "## We have to give uniform noise to some training examples to prevent the model from returning one of the most frequent tags always!!\n",
    "#uniform_noise = torch.BoolTensor(tag_frequencies.size(0))\n",
    "#uniform_noise[:] = True\n",
    "#shuffle_tensor = torch.randperm(tag_frequencies.size(0))[:int(tag_frequencies.size(0)*0.7)]\n",
    "#uniform_noise[shuffle_tensor] = False\n",
    "#tag_frequencies_copy[torch.logical_and(uniform_noise, word_frequencies_target < 0.1), :] = 0.0000001\n",
    "\n",
    "#sm = torch.sum(tag_frequencies_copy, dim=1)\n",
    "#normalized_tag_frequencies = (tag_frequencies_copy.transpose(1,0) / sm).transpose(1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "\n",
    "def create_model(train_gnn_dataset, grc_gnn_dataset, heb_gnn_dataset, blinker_gnn_dataset, test_gnn_dataset,\n",
    "                tag_frequencies=False, use_transformers=False, train_word_embedding=False, mask_language=True):\n",
    "    global model, criterion, optimizer\n",
    "\n",
    "    features = train_dataset.features[:]\n",
    "    #features.append(afeatures.PassFeature(name='posTAG', dim=len(postag_map)))\n",
    "    if tag_frequencies:\n",
    "        features.append(afeatures.MappingFeature(len(postag_map), 'tag_priors', freeze=True))\n",
    "    features[9].freeze = not train_word_embedding\n",
    "    print('len features', len(features))\n",
    "    \n",
    "    train_data_loader = DataLoader(train_gnn_dataset, batch_size=1, shuffle=True)\n",
    "    grc_data_loader = DataLoader(grc_gnn_dataset, batch_size=1, shuffle=True)\n",
    "    heb_data_loader = DataLoader(heb_gnn_dataset, batch_size=1, shuffle=True)\n",
    "    blinker_data_loader = DataLoader(blinker_gnn_dataset, batch_size=1, shuffle=True)\n",
    "    test_data_loader = DataLoader(test_gnn_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "    clean_memory()\n",
    "    drop_out = 0\n",
    "    n_head = 1\n",
    "    in_dim = sum(t.out_dim for t in features)\n",
    "\n",
    "\n",
    "    channels = 512\n",
    "\n",
    "    decoder_in_dim = n_head * channels \n",
    "\n",
    "    # model = torch.load('/mounts/work/ayyoob/models/gnn/checkpoint/gnn_512_flggll_word_halfTrain_nofeatlinear_encoderlineear_decoderonelayer20210910-235352-.pickle')\n",
    "    if use_transformers:\n",
    "        decoder = POSDecoderTransformer(decoder_in_dim, decoder_in_dim*2, len(postag_map)).to(dev2)\n",
    "    else:\n",
    "        decoder = POSDecoder(decoder_in_dim, decoder_in_dim*2, len(postag_map))\n",
    "        \n",
    "    model = pyg_nn.GAE(Encoder(in_dim, channels, features, n_head, has_tagfreq_feature=tag_frequencies), decoder).to(dev)\n",
    "\n",
    "\n",
    "    #vgg = models.vgg16()\n",
    "    #summary(vgg, (3, 224, 224))\n",
    "    if use_transformers:\n",
    "        decoder.to(dev2)\n",
    "\n",
    "    # model.to(dev)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=0.0001)\n",
    "\n",
    "    torch.set_printoptions(edgeitems=5)\n",
    "    print(\"model params - decoder params - conv1\", sum(p.numel() for p in model.parameters()), sum(p.numel() for p in decoder.parameters()))\n",
    "\n",
    "    for epoch in range(1, 2):\n",
    "        print(f\"\\n----------------epoch {epoch} ---------------\")\n",
    "        \n",
    "        train(epoch, train_data_loader, mask_language, engtest_data_loader)\n",
    "        train(epoch, grc_data_loader, mask_language, engtest_data_loader)\n",
    "        train(epoch, heb_data_loader, mask_language, engtest_data_loader)\n",
    "        train(epoch, blinker_data_loader, mask_language, engtest_data_loader)\n",
    "        save_model(model, f'posfeat{tag_frequencies}_transformer{use_transformers}_trainWE{train_word_embedding}_maskLang{mask_language}_epoch{epoch}')\n",
    "        test(epoch, test_data_loader, mask_language) \n",
    "        clean_memory()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len features 10\n",
      "model params - decoder params - conv1 237862513 1592337\n",
      "\n",
      "----------------epoch 1 ---------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 498/57706 [00:38<1:16:52, 12.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 60792.10155946016\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:14<00:00, 16.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.681423030627257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 997/57706 [01:33<1:03:50, 14.81it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 41461.1582795158\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:13<00:00, 18.05it/s]t/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7302394008292096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1498/57706 [02:28<1:24:13, 11.12it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 41308.60204675794\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:14<00:00, 17.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7190049485087602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1999/57706 [03:23<1:13:46, 12.59it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 38717.00278094411\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:15<00:00, 16.21it/s]it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7164638223886586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2497/57706 [04:21<1:18:27, 11.73it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 35806.365319907665\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:13<00:00, 17.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7374615487494984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 2999/57706 [05:15<1:14:07, 12.30it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 36571.082430224866\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:13<00:00, 18.34it/s]it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7396014444295841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 3498/57706 [06:11<55:15, 16.35it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 34578.3864111295\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:13<00:00, 17.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7409388792296375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 3999/57706 [07:07<59:58, 14.92it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 35110.236918091774\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:14<00:00, 17.39it/s]/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7412063661896483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 4498/57706 [08:07<1:03:37, 13.94it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 35730.45427325368\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:13<00:00, 18.17it/s]it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7444162097097766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 4998/57706 [09:02<1:02:25, 14.07it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 34052.00408928841\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:14<00:00, 16.70it/s]\n",
      "  9%|▊         | 5001/57706 [09:19<28:01:49,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7733048013909322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 5499/57706 [09:58<59:44, 14.56it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 36352.707267828286\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:13<00:00, 18.29it/s]/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7698274709107931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5997/57706 [10:54<1:24:26, 10.21it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 34441.14432041347\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:13<00:00, 18.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7644777317105791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 6498/57706 [11:51<54:55, 15.54it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 35073.933283150196\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:13<00:00, 17.99it/s]\n",
      " 11%|█▏        | 6502/57706 [12:07<22:13:02,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7547144576701886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 6999/57706 [12:48<1:11:11, 11.87it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 35425.1607362628\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:13<00:00, 17.95it/s]it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7601979403504079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 7498/57706 [13:44<1:11:15, 11.74it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 32236.675681129098\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:13<00:00, 18.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7521733315500869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 7998/57706 [14:39<1:18:32, 10.55it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 32964.19366782904\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:13<00:00, 18.07it/s]it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7672863447906915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 8498/57706 [15:35<1:15:56, 10.80it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 34060.01130712032\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:15<00:00, 16.26it/s]it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7638090143105524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 8999/57706 [16:32<53:05, 15.29it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 32805.055265404284\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:13<00:00, 18.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7832018189113281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 9498/57706 [17:28<1:05:38, 12.24it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 32272.189907018095\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:15<00:00, 16.30it/s]it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7734385448709375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 9999/57706 [18:26<1:13:31, 10.81it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 32108.60938668251\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:13<00:00, 17.94it/s]it/s]\n",
      " 17%|█▋        | 10003/57706 [18:42<21:02:09,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7695599839507824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 10498/57706 [19:22<1:14:47, 10.52it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 33036.3243214041\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:14<00:00, 17.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7626053229905042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 10997/57706 [20:14<45:56, 16.94it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 34477.23181404732\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:09<00:00, 26.08it/s]\n",
      " 19%|█▉        | 11002/57706 [20:26<13:46:30,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7763809014310552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 11497/57706 [20:57<36:51, 20.90it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 33724.44744684547\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:09<00:00, 25.09it/s]\n",
      " 20%|█▉        | 11503/57706 [21:08<10:40:33,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7861441754714458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 11997/57706 [21:37<44:10, 17.24it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 32829.86324210465\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:09<00:00, 26.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7722348535508894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 12498/57706 [22:19<45:45, 16.46it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 32987.28686556965\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:09<00:00, 25.85it/s]\n",
      " 22%|██▏       | 12498/57706 [22:29<45:45, 16.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7836030493513442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 12997/57706 [22:58<41:58, 17.75it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 32020.25784060359\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:10<00:00, 23.70it/s]\n",
      " 23%|██▎       | 12997/57706 [23:10<41:58, 17.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7845392537113816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 13499/57706 [23:41<1:02:03, 11.87it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 32685.025623455644\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:10<00:00, 24.24it/s]\n",
      " 23%|██▎       | 13503/57706 [23:53<15:45:01,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7828005884713121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 13998/57706 [24:23<46:03, 15.81it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 33657.02029967308\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:10<00:00, 24.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7632740403905309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 14498/57706 [25:05<46:25, 15.51it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 31361.95577391982\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:10<00:00, 24.56it/s]\n",
      " 25%|██▌       | 14502/57706 [25:17<14:39:40,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7691587535107663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 14999/57706 [25:45<53:42, 13.25it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 32199.8413085863\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:16<00:00, 14.77it/s]t/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7818643841112746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 15499/57706 [26:52<1:01:24, 11.45it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 31715.11689314805\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:17<00:00, 13.90it/s]5it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7783870536311355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 15999/57706 [28:02<1:01:54, 11.23it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 31219.561755333096\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:18<00:00, 13.36it/s]3it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7773171057910927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 16499/57706 [29:12<1:02:49, 10.93it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 31446.97399880737\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:17<00:00, 13.94it/s]3it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7700949578708038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 16998/57706 [30:23<1:03:40, 10.65it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 32279.265567600727\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:18<00:00, 13.41it/s]5it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7936338103517454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 17499/57706 [31:33<57:03, 11.74it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 30920.391665201634\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:18<00:00, 13.38it/s]t/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7779858231911194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 17998/57706 [32:41<45:38, 14.50it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 32226.608943078667\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:12<00:00, 20.75it/s]\n",
      " 31%|███       | 18001/57706 [32:54<17:48:19,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7757121840310285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 18499/57706 [33:30<44:45, 14.60it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 30466.84911365807\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:12<00:00, 20.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7727698274709108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 18999/57706 [34:19<44:46, 14.41it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 31123.23767172359\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:14<00:00, 17.17it/s]t/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7786545405911461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 19498/57706 [35:21<52:26, 12.14it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 31737.671187520027\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:17<00:00, 14.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.793098836431724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 19999/57706 [36:26<55:23, 11.35it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 30966.438239596784\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:16<00:00, 15.29it/s]t/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7882840711515313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 20498/57706 [37:35<1:07:51,  9.14it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 32172.9316954948\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:17<00:00, 14.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7726360839909054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 20998/57706 [38:44<59:18, 10.32it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 30431.26906323433\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:17<00:00, 14.26it/s]t/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7845392537113816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 21498/57706 [39:50<49:38, 12.15it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 31304.073297854513\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:19<00:00, 12.96it/s]t/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7817306406312692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 21999/57706 [40:56<55:52, 10.65it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 30403.621094852686\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:16<00:00, 15.30it/s]t/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7774508492710981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 22499/57706 [42:02<49:59, 11.74it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 31362.616195239127\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:16<00:00, 15.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7809281797512371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 22998/57706 [43:08<1:04:47,  8.93it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 30669.524622805417\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:17<00:00, 14.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7803932058312157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 23497/57706 [44:12<53:00, 10.76it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 31071.832025129348\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:20<00:00, 12.43it/s]t/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7932325799117294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 23999/57706 [45:19<42:15, 13.29it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 29946.477564591914\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:16<00:00, 15.00it/s]t/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7777183362311088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 24498/57706 [46:24<47:50, 11.57it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 29947.293967485428\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:16<00:00, 15.52it/s]\n",
      " 42%|████▏     | 24498/57706 [46:42<47:50, 11.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7856092015514243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 24997/57706 [47:29<36:37, 14.89it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 29856.787325300276\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:16<00:00, 15.49it/s]t/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7818643841112746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 25499/57706 [48:35<52:35, 10.21it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 31261.104525879025\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:16<00:00, 15.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7842717667513709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 25999/57706 [49:40<54:52,  9.63it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 30918.30260427296\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:17<00:00, 14.53it/s]t/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7975123712719004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 26499/57706 [50:47<50:52, 10.22it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 31431.326733484864\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:16<00:00, 15.54it/s]t/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.776648388391066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 26998/57706 [51:52<45:03, 11.36it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 30042.864431351423\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:15<00:00, 15.99it/s]t/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7731710579109269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 27498/57706 [52:57<58:16,  8.64it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 30816.291095875204\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:16<00:00, 15.31it/s]t/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7759796709910391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▊     | 27998/57706 [54:02<41:19, 11.98it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 31299.452487632632\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:19<00:00, 12.71it/s]t/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7936338103517454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 28498/57706 [55:06<35:20, 13.77it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 29201.13902322203\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:15<00:00, 15.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7981810886719273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 28998/57706 [56:10<43:53, 10.90it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 29006.763607326895\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:16<00:00, 15.32it/s]t/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.785074227631403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 29498/57706 [57:15<44:03, 10.67it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 29810.281037926674\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:16<00:00, 15.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7822656145512906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 29999/57706 [58:19<39:56, 11.56it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 31283.9463442564\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:18<00:00, 13.67it/s]t/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7868128928714725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 30499/57706 [59:26<28:09, 16.10it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 29055.69918948412\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:13<00:00, 18.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7799919753911997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▎    | 30997/57706 [1:00:23<30:26, 14.62it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 28491.436715815216\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:13<00:00, 18.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.8088805670723552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 31498/57706 [1:01:15<27:21, 15.96it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 30318.052173748612\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:09<00:00, 25.50it/s]\n",
      " 55%|█████▍    | 31502/57706 [1:01:27<8:11:26,  1.13s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.8027283669921091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 31998/57706 [1:01:59<23:47, 18.01it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 30526.386958748102\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:09<00:00, 25.84it/s]\n",
      " 55%|█████▌    | 32003/57706 [1:02:10<6:29:37,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7798582319111943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 32498/57706 [1:02:41<28:46, 14.60it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 29547.272876989096\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:09<00:00, 26.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7842717667513709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 32999/57706 [1:03:23<23:52, 17.25it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 29155.111212275922\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:09<00:00, 27.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.8037983148321519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 33497/57706 [1:04:05<19:57, 20.21it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 29703.844828650355\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:10<00:00, 24.84it/s]\n",
      " 58%|█████▊    | 33502/57706 [1:04:17<6:29:20,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7955062190718203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 33998/57706 [1:04:49<20:29, 19.28it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 29525.418810538948\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:09<00:00, 26.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7905577103116224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 34499/57706 [1:05:32<21:21, 18.11it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 29876.798161805607\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:09<00:00, 26.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.8023271365520931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 34999/57706 [1:06:14<24:00, 15.76it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 29990.65583114326\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:09<00:00, 27.07it/s]\n",
      " 61%|██████    | 34999/57706 [1:06:25<24:00, 15.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.793098836431724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 35499/57706 [1:06:58<30:10, 12.27it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 31067.214357439894\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:09<00:00, 26.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7945700147117828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 35997/57706 [1:07:40<24:43, 14.63it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 27797.19819731172\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:09<00:00, 25.39it/s]\n",
      " 62%|██████▏   | 36003/57706 [1:07:51<5:50:33,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7944362712317774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 36499/57706 [1:08:26<24:22, 14.50it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 29384.374792933464\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:10<00:00, 24.85it/s]\n",
      " 63%|██████▎   | 36501/57706 [1:08:38<10:14:13,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7963086799518524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 36999/57706 [1:09:09<30:24, 11.35it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 29078.484402140602\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:09<00:00, 25.48it/s]\n",
      " 64%|██████▍   | 37004/57706 [1:09:20<6:11:00,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7953724755918149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 37499/57706 [1:09:52<19:57, 16.88it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 28846.706269759685\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:09<00:00, 26.87it/s]\n",
      " 65%|██████▍   | 37503/57706 [1:10:03<6:13:02,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.8047345191921894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 37998/57706 [1:10:34<22:34, 14.55it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 29915.487880647182\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:09<00:00, 25.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7868128928714725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 38498/57706 [1:11:15<19:36, 16.33it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 28954.12161179632\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:09<00:00, 26.21it/s]\n",
      " 67%|██████▋   | 38502/57706 [1:11:27<6:10:21,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7936338103517454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 38997/57706 [1:11:58<20:21, 15.32it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 29296.288713146\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:09<00:00, 26.27it/s]\n",
      " 68%|██████▊   | 39002/57706 [1:12:09<4:51:46,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7937675538317507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 39497/57706 [1:12:40<19:29, 15.57it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 29806.223991628736\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:09<00:00, 26.30it/s]\n",
      " 68%|██████▊   | 39500/57706 [1:12:51<6:45:18,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7844055102313762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 39999/57706 [1:13:22<19:48, 14.90it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 28337.276672810316\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:09<00:00, 25.88it/s]\n",
      " 69%|██████▉   | 40003/57706 [1:13:34<5:43:44,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.8028621104721145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 40499/57706 [1:14:04<13:36, 21.07it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 29446.786886418326\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:09<00:00, 25.59it/s]\n",
      " 70%|███████   | 40502/57706 [1:14:16<5:35:15,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7936338103517454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 40999/57706 [1:14:48<23:14, 11.98it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 29189.354666974396\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:10<00:00, 24.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.8058044670322322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 41498/57706 [1:15:30<18:02, 14.97it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 28197.966673851013\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:09<00:00, 27.63it/s]\n",
      " 72%|███████▏  | 41503/57706 [1:15:41<4:09:40,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.8078106192323125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 41998/57706 [1:16:12<17:22, 15.07it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 29171.886109143496\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:13<00:00, 18.82it/s]\n",
      " 73%|███████▎  | 41998/57706 [1:16:27<17:22, 15.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7944362712317774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▎  | 42498/57706 [1:17:07<23:10, 10.93it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 29212.413708478212\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:14<00:00, 17.15it/s]3it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7960411929918416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 42998/57706 [1:18:02<19:07, 12.82it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 28675.50098800659\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:13<00:00, 18.63it/s]\n",
      " 75%|███████▍  | 43002/57706 [1:18:17<6:30:14,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7940350407917613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 43499/57706 [1:18:59<17:00, 13.92it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 29854.08224734664\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:14<00:00, 17.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7929650929517186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 43999/57706 [1:19:54<19:26, 11.75it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 29510.54767908156\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:14<00:00, 16.89it/s]5it/s]\n",
      " 76%|███████▋  | 44001/57706 [1:20:10<8:53:13,  2.33s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.8092817975123713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 44499/57706 [1:20:50<18:53, 11.65it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 29217.616110488772\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:13<00:00, 18.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.8067406713922697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 44998/57706 [1:21:45<17:18, 12.24it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 30026.592356693\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:13<00:00, 18.74it/s]4it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.8037983148321519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 45498/57706 [1:22:42<16:01, 12.70it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 28422.209765970707\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:13<00:00, 18.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.8134278453925371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 45999/57706 [1:23:37<14:35, 13.37it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 29034.758199363947\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:14<00:00, 16.67it/s]7it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7944362712317774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 46498/57706 [1:24:33<12:44, 14.66it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 29049.520737092942\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:13<00:00, 19.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.809549284472382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████▏ | 46999/57706 [1:25:27<19:52,  8.98it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 29414.77227556333\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:13<00:00, 18.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7995185234719807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 47499/57706 [1:26:22<14:25, 11.79it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 29522.839936850592\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:15<00:00, 16.56it/s]\n",
      " 82%|████████▏ | 47499/57706 [1:26:38<14:25, 11.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.8119566671124783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 47999/57706 [1:27:14<13:19, 12.14it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 28847.363803632557\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:13<00:00, 18.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.8040658017921626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 48498/57706 [1:28:10<12:07, 12.67it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 29585.21772081405\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:14<00:00, 16.79it/s]\n",
      " 84%|████████▍ | 48502/57706 [1:28:27<4:28:17,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.793098836431724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 48998/57706 [1:29:06<13:52, 10.46it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 29198.767078474164\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:13<00:00, 18.82it/s]6it/s]\n",
      " 85%|████████▍ | 49000/57706 [1:29:21<5:28:31,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.8000534973920022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 49499/57706 [1:30:02<10:19, 13.24it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 28942.768796622753\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:13<00:00, 18.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7944362712317774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 49998/57706 [1:31:00<10:21, 12.40it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 29854.20639207959\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:13<00:00, 18.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.801524675672061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 50499/57706 [1:31:56<10:25, 11.52it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 29821.06729345396\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:15<00:00, 16.11it/s]2it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.8043332887521734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 50998/57706 [1:32:52<07:36, 14.71it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 29118.702739151195\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:13<00:00, 18.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.8112879497124516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 51499/57706 [1:33:49<07:19, 14.14it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 29554.597927093506\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:13<00:00, 18.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.804199545272168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 51998/57706 [1:34:43<08:28, 11.22it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 28355.460974171758\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:14<00:00, 17.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.8054032365922161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 52498/57706 [1:35:40<06:07, 14.16it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 30726.339223045507\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:14<00:00, 17.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7888190450715528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 52997/57706 [1:36:36<05:48, 13.49it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 29731.466311063617\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:12<00:00, 19.44it/s]9it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7995185234719807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 53499/57706 [1:37:31<04:43, 14.84it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 28629.71487067826\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:13<00:00, 18.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7991172930319647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▎| 53999/57706 [1:38:26<04:25, 13.97it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 29594.03818562627\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:15<00:00, 16.03it/s]7it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7953724755918149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 54498/57706 [1:39:23<04:26, 12.03it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 28837.669435851276\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:12<00:00, 19.65it/s]\n",
      " 94%|█████████▍| 54502/57706 [1:39:39<1:22:07,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.8062056974722482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 54999/57706 [1:40:20<03:35, 12.55it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 29995.68530363217\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:13<00:00, 19.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7964424234318577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 55499/57706 [1:41:17<03:19, 11.07it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 29116.868619788438\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:12<00:00, 19.62it/s]7it/s]\n",
      " 96%|█████████▌| 55500/57706 [1:41:31<1:34:25,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7967099103918684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 55999/57706 [1:42:11<01:46, 16.09it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 28866.955785244703\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:14<00:00, 17.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.8146315367125853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 56499/57706 [1:43:08<01:24, 14.29it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 29541.835002522916\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:11<00:00, 21.42it/s]9it/s]\n",
      " 98%|█████████▊| 56500/57706 [1:43:21<41:44,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.8098167714323927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 56998/57706 [1:44:00<00:48, 14.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 29635.474113680422\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:11<00:00, 22.00it/s]\n",
      " 99%|█████████▉| 57001/57706 [1:44:13<16:11,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.8100842583924034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 57499/57706 [1:44:51<00:15, 13.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 27889.344849720597\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:08<00:00, 28.66it/s]\n",
      "100%|█████████▉| 57505/57706 [1:45:01<02:43,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.8090143105523606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 57706/57706 [1:45:12<00:00,  9.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total train loss: 12154.4075050354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 499/2192 [00:39<02:17, 12.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 40078.94637584686\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:09<00:00, 25.71it/s]\n",
      " 23%|██▎       | 501/2192 [00:50<48:57,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.8033970843921359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 999/2192 [01:28<01:24, 14.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 40443.52976617962\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:10<00:00, 23.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.8067406713922697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 1498/2192 [02:18<00:46, 14.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 38933.15093395114\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:07<00:00, 31.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.8078106192323125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 1998/2192 [03:08<00:16, 11.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 41104.44333682582\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:08<00:00, 30.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.8009897017520395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2192/2192 [03:32<00:00, 10.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total train loss: 15794.375205144286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 499/4993 [00:25<03:09, 23.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 24111.327615510672\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:09<00:00, 27.53it/s]\n",
      " 10%|█         | 503/4993 [00:36<1:06:24,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.8201150193928046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 999/4993 [00:59<03:45, 17.71it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 22250.933524686843\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:09<00:00, 27.46it/s]\n",
      " 20%|██        | 1003/4993 [01:09<1:05:58,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.8090143105523606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 1499/4993 [01:34<02:28, 23.48it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 22975.5532618016\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:09<00:00, 27.48it/s]\n",
      " 30%|███       | 1505/4993 [01:45<41:39,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.8114216931924568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 1999/4993 [02:08<02:53, 17.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 23137.5597955361\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:11<00:00, 21.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.8146315367125853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2498/4993 [02:45<02:00, 20.78it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 23817.35313051939\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:09<00:00, 27.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.8136953323525478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 2998/4993 [03:19<01:44, 19.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 21590.505381432362\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:10<00:00, 22.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.815701484552628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 3497/4993 [03:55<01:23, 18.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 23973.96987787634\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:08<00:00, 27.86it/s]\n",
      " 70%|███████   | 3503/4993 [04:06<19:57,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.8199812759127992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 3998/4993 [04:30<00:39, 25.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 22794.724494640715\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:08<00:00, 28.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.8187775845927511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 4497/4993 [05:04<00:25, 19.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 22915.38640972972\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:09<00:00, 26.61it/s]\n",
      " 90%|█████████ | 4500/4993 [05:15<09:14,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.8223886585528956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4993/4993 [05:40<00:00, 14.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total train loss: 21917.511179342866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 497/641 [00:33<00:08, 17.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 31936.211573064327\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:09<00:00, 27.68it/s]\n",
      " 78%|███████▊  | 503/641 [00:44<02:04,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.8203825063528153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 641/641 [00:53<00:00, 12.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total train loss: 8679.027367591858\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:09<00:00, 27.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.8100842583924034\n"
     ]
    }
   ],
   "source": [
    "create_model(gnn_dataset_train_pos, gnn_dataset_grc_pos, gnn_dataset_heb_pos, gnn_dataset_blinker_pos, gnn_dataset_engtest_pos,\n",
    "train_word_embedding=False, mask_language=True, use_transformers=False, tag_frequencies=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24078/24078 [11:31<00:00, 34.85it/s]\n",
      "100%|██████████| 783/783 [00:31<00:00, 25.05it/s]\n",
      "100%|██████████| 2225/2225 [00:52<00:00, 42.48it/s]\n",
      "100%|██████████| 250/250 [00:08<00:00, 28.63it/s]\n",
      "100%|██████████| 24078/24078 [11:03<00:00, 36.31it/s]\n",
      "100%|██████████| 783/783 [00:32<00:00, 24.19it/s]\n",
      "100%|██████████| 250/250 [00:07<00:00, 32.35it/s]\n",
      "100%|██████████| 24078/24078 [12:48<00:00, 31.31it/s]\n",
      "100%|██████████| 783/783 [00:37<00:00, 21.16it/s]\n",
      "100%|██████████| 2225/2225 [01:03<00:00, 35.10it/s]\n",
      "100%|██████████| 250/250 [00:09<00:00, 26.78it/s]\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(posutil)\n",
    "target_langs = ['yor-x-bible-2010', 'tam-x-bible-newworld', 'fin-x-bible-helfi']\n",
    "for lang in target_langs:\n",
    "    posutil.generate_target_lang_tags(model, lang, f\"new_posfeatFalse_transformerFalse_trainWEFalse\", True, train_dataset, grc_test_dataset, heb_test_dataset, blinker_test_dataset,\n",
    "     train_data_loader_bigbatch, grc_data_loader_bigbatch, heb_data_loader_bigbatch, blinker_data_loader_bigbatch, DataEncoder)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_pos_node_cover_ext' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-535857bd129b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;31m# posutil.generate_target_lang_tags_all_models(['yor-x-bible-2010', 'tam-x-bible-newworld', 'fin-x-bible-helfi'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m \u001b[0mfinetune_and_generate_for_target_lang\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/mounts/work/ayyoob/models/gnn/checkpoint/postagging/pos_tagging_posfeatTrue_transformerTru6Lresidual_trainWETrue_maskLangFalse_epoch3_20220218-101130.pickle'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'yor-x-bible-2010'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-28-535857bd129b>\u001b[0m in \u001b[0;36mfinetune_and_generate_for_target_lang\u001b[0;34m(model_path, target_edition)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mtarget_train_node_cover\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_language_node_cover\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_pos_node_cover_ext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_edition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mtarget_grc_node_cover\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_language_node_cover\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrc_pos_node_cover_ext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_edition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrc_test_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mtarget_heb_node_cover\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_language_node_cover\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheb_pos_node_cover_ext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_edition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheb_test_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_pos_node_cover_ext' is not defined"
     ]
    }
   ],
   "source": [
    "# model = torch.load('/mounts/work/ayyoob/models/gnn/checkpoint/postagging/pos_tagging_posfeatTrue_transformerTrue_trainWETrue_maskLangFalse_epoch3_20220218-101130.pickle')\n",
    "# test(1, engtest_data_loader, mask_language=False) \n",
    "\n",
    "importlib.reload(posutil)\n",
    "def get_language_node_cover(all_node_cover, target_edition, dataset):\n",
    "    nodes_map = dataset.nodes_map\n",
    "    res = collections.defaultdict(list)\n",
    "\n",
    "    if target_edition in nodes_map:\n",
    "        for verse in all_node_cover:\n",
    "            if verse in nodes_map[target_edition]:\n",
    "                lang_nodes = list(nodes_map[target_edition][verse].values())\n",
    "                for tok in all_node_cover[verse]:\n",
    "                    if tok in lang_nodes:\n",
    "                        res[verse].append(tok)\n",
    "    \n",
    "    return res\n",
    "    \n",
    "\n",
    "def finetune_and_generate_for_target_lang(model_path, target_edition):\n",
    "    global model, criterion, optimizer\n",
    "    \n",
    "    target_train_node_cover = get_language_node_cover(train_pos_node_cover_ext, target_edition, train_dataset)\n",
    "    target_grc_node_cover = get_language_node_cover(grc_pos_node_cover_ext, target_edition, grc_test_dataset)\n",
    "    target_heb_node_cover = get_language_node_cover(heb_pos_node_cover_ext, target_edition, heb_test_dataset)\n",
    "    target_blinker_node_cover = get_language_node_cover(blinker_pos_node_cover_ext, target_edition, blinker_test_dataset)\n",
    "    \n",
    "\n",
    "    train_ds, grc_ds, heb_ds, blinker_ds = create_me_a_gnn_dataset_you_stupid(\n",
    "            [target_train_node_cover, target_grc_node_cover, target_heb_node_cover, target_blinker_node_cover], \n",
    "            [train_pos_labels_ext, grc_pos_labels_ext,  heb_pos_labels_ext, blinker_pos_labels_ext], editions=[target_edition])\n",
    "    \n",
    "    train_data_loader = DataLoader(train_ds, shuffle=True)\n",
    "    grc_data_loader = DataLoader(grc_ds, shuffle=True)\n",
    "    heb_data_loader = DataLoader(heb_ds, shuffle=True)\n",
    "    blinker_data_loader = DataLoader(blinker_ds, shuffle=True)\n",
    "\n",
    "    # model = torch.load(model_path)\n",
    "    # criterion = nn.CrossEntropyLoss()\n",
    "    # optimizer = torch.optim.AdamW(model.parameters(), lr=0.00001)\n",
    "    # train(1, train_data_loader, mask_language=False, test_data_loader=blinker_data_loader, max_batches=100)\n",
    "    # posutil.generate_target_lang_tags(model, target_edition, 'posfeatTrue_transformerTrue6layerresidual_trainWEFalse_finetune100', False, \n",
    "    #         train_dataset, grc_test_dataset, heb_test_dataset, blinker_test_dataset, train_data_loader_bigbatch, grc_data_loader_bigbatch, heb_data_loader_bigbatch, blinker_data_loader_bigbatch,\n",
    "    #         DataEncoder)\n",
    "    # model = None\n",
    "    # clean_memory\n",
    "\n",
    "    # model = torch.load(model_path)\n",
    "    # criterion = nn.CrossEntropyLoss()\n",
    "    # optimizer = torch.optim.AdamW(model.parameters(), lr=0.00001)\n",
    "    # train(1, train_data_loader, mask_language=False, test_data_loader=blinker_data_loader, max_batches=1000)\n",
    "    posutil.generate_target_lang_tags(model, target_edition, 'posfeatTrue_transformerTrue6layerresidual_trainWEFalse_finetune1000', False, \n",
    "            train_dataset, grc_test_dataset, heb_test_dataset, blinker_test_dataset, train_data_loader_bigbatch, grc_data_loader_bigbatch, heb_data_loader_bigbatch, blinker_data_loader_bigbatch,\n",
    "            DataEncoder)\n",
    "    model = None\n",
    "    clean_memory\n",
    "\n",
    "    model = torch.load(model_path)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=0.00001)\n",
    "    train(1, train_data_loader, mask_language=False, test_data_loader=blinker_data_loader, max_batches=10000)\n",
    "    posutil.generate_target_lang_tags(model, target_edition, 'posfeatTrue_transformerTrue6layerresidual_trainWEFalse_finetune10000', False, \n",
    "            train_dataset, grc_test_dataset, heb_test_dataset, blinker_test_dataset, train_data_loader_bigbatch, grc_data_loader_bigbatch, heb_data_loader_bigbatch, blinker_data_loader_bigbatch,\n",
    "            DataEncoder)\n",
    "    model = None\n",
    "    clean_memory\n",
    "\n",
    "    model = torch.load(model_path)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=0.00001)\n",
    "    train(1, train_data_loader, mask_language=False, test_data_loader=blinker_data_loader)\n",
    "    train(1, grc_data_loader, mask_language=False, test_data_loader=blinker_data_loader)\n",
    "    train(1, heb_data_loader, mask_language=False, test_data_loader=blinker_data_loader)\n",
    "    train(1, blinker_data_loader, mask_language=False, test_data_loader=blinker_data_loader)\n",
    "    posutil.generate_target_lang_tags(model, target_edition, 'posfeatTrue_transformerTrue6layerresidual_trainWEFalse_finetuneALL', False, \n",
    "            train_dataset, grc_test_dataset, heb_test_dataset, blinker_test_dataset, train_data_loader_bigbatch, grc_data_loader_bigbatch, heb_data_loader_bigbatch, blinker_data_loader_bigbatch,\n",
    "            DataEncoder)\n",
    "\n",
    "\n",
    "def generate_target_lang_tags_all_models(target_langs):\n",
    "    global model\n",
    "    model = torch.load('/mounts/work/ayyoob/models/gnn/checkpoint/postagging/pos_tagging_posfeatFalse_transformerFalse_trainWEFalse_maskLangTrue_20220209-201345.pickle', map_location=torch.device('cpu')).to(dev)\n",
    "    test(0, blinker_data_loader_bigbatch, True)\n",
    "    for lang in target_langs:\n",
    "        posutil.generate_target_lang_tags(lang,  f\"posfeatFalse_transformerFalse_trainWEFalse\", True)\n",
    "\n",
    "# posutil.generate_target_lang_tags_all_models(['yor-x-bible-2010', 'tam-x-bible-newworld', 'fin-x-bible-helfi'])\n",
    "finetune_and_generate_for_target_lang('/mounts/work/ayyoob/models/gnn/checkpoint/postagging/pos_tagging_posfeatTrue_transformerTru6Lresidual_trainWETrue_maskLangFalse_epoch3_20220218-101130.pickle', 'yor-x-bible-2010')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gnn_dataset_train_pos_ext, gnn_dataset_grc_pos_ext, gnn_dataset_heb_pos_ext, gnn_dataset_blinker_pos_ext = create_me_a_gnn_dataset_you_stupid([ train_pos_node_cover_ext, grc_pos_node_cover_ext, heb_pos_node_cover_ext, blinker_pos_node_cover_ext]\n",
    "#    , [train_pos_labels_ext, grc_pos_labels_ext, heb_pos_labels_ext, blinker_pos_labels_ext])\n",
    "#create_model(gnn_dataset_train_pos_ext, gnn_dataset_grc_pos_ext, gnn_dataset_heb_pos_ext, gnn_dataset_blinker_pos_ext, gnn_dataset_blinker_pos_bigbatch,\n",
    "#    train_word_embedding=False, mask_language=False, use_transformers=True, tag_frequencies=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#i = sag\n",
    "#batch = khar\n",
    "#verse = gav\n",
    "#print(i, verse)\n",
    "\n",
    "#keys = list(gnn_dataset.verse_info.keys())\n",
    "\n",
    "#gnn_dataset.verse_info[verse]\n",
    "#save_model(model, 'freeze-embedding_noLang')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:16<00:00, 15.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 0, total:52256 ACC: 0.1478107777097367\n"
     ]
    }
   ],
   "source": [
    "#initial_model = model.to('cpu')\n",
    "#model = torch.load('/mounts/work/ayyoob/models/gnn/checkpoint/postagging/pos_tagging_posfeatTrue_transformerFalse_trainWEFalse_maskLangTrue_20220210-173912.pickle')\n",
    "#torch.cuda.set_device(0)\n",
    "#model.to(dev)\n",
    "#epoch = 0\n",
    "#test_data_loader = DataLoader(gnn_dataset_blinker_pos_bigbatch, batch_size=1, shuffle=False)\n",
    "#test(epoch, test_data_loader, mask_language=True)\n",
    "##yoruba_postags = generate_target_lang_tags('yor-x-bible-2010', f\"posfeatFalse_transformerFalse_trainWEFalse\", True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##importlib.reload(afeatures)\n",
    "#initial_model = model\n",
    "#torch.cuda.set_device(1)\n",
    "#create_model(gnn_dataset_train_pos, gnn_dataset_grc_pos, gnn_dataset_heb_pos, gnn_dataset_blinker_pos, gnn_dataset_blinker_pos_bigbatch, tag_frequencies=True)\n",
    "## yoruba_postags = generate_target_lang_tags('yor-x-bible-2010', f\"posfeatTrue_transformerFalse_trainWEFalse\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len features 11\n",
      "model params - decoder params - conv1 277911011 1592337\n",
      "\n",
      "----------------epoch 1 ---------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 498/58044 [00:55<1:17:38, 12.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 61841.90937706083\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:08<00:00, 28.45it/s]\n",
      "  1%|          | 502/58044 [01:06<18:54:26,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.684900361107396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 998/58044 [01:48<1:15:17, 12.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 43130.26362814009\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:04<00:00, 55.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7349204226293968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1498/58044 [02:39<1:19:49, 11.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 38608.35494910739\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:04<00:00, 53.10it/s]\n",
      "  3%|▎         | 1501/58044 [02:45<13:45:12,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7581917881503276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1998/58044 [03:28<1:15:55, 12.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 35195.79320020508\n",
      "testing 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:04<00:00, 53.17it/s]\n",
      "  3%|▎         | 2002/58044 [03:35<11:29:29,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 1, total:7477 ACC: 0.7442824662297713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2369/58044 [04:06<1:36:23,  9.63it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-e22bf5440e72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m create_model(gnn_ds_train_pos_ext, gnn_ds_grc_pos_ext, gnn_ds_heb_pos_ext, gnn_ds_blinker_pos_ext, gnn_dataset_blinker_pos_bigbatch, tag_frequencies=True\n\u001b[0;32m----> 6\u001b[0;31m     , use_transformers=False, train_word_embedding=True, mask_language=False)\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# yoruba_postags = generate_target_lang_tags('yor-x-bible-2010', f\"posfeatTrue_transformerTrue_trainWETrue\", False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-1c1cc87f9dc3>\u001b[0m in \u001b[0;36mcreate_model\u001b[0;34m(train_gnn_dataset, grc_gnn_dataset, heb_gnn_dataset, blinker_gnn_dataset, test_gnn_dataset, tag_frequencies, use_transformers, train_word_embedding, mask_language)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n----------------epoch {epoch} ---------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_language\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrc_data_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_language\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheb_data_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_language\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-18d2fe8ea2ae>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch, data_loader, mask_language, max_batches)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# Gradient accumulation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/multalign_graph/lib/python3.7/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/multalign_graph/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/multalign_graph/lib/python3.7/site-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    119\u001b[0m                     \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m                     \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m                     group['eps'])\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/multalign_graph/lib/python3.7/site-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36madamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m         \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0;31m# Maintains the maximum of all 2nd moment running avg. till now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "torch.cuda.set_device(4)\n",
    "gnn_ds_train_pos_ext, gnn_ds_grc_pos_ext, gnn_ds_heb_pos_ext, gnn_ds_blinker_pos_ext = create_me_a_gnn_dataset_you_stupid([train_pos_node_cover_ext, grc_pos_node_cover_ext, heb_pos_node_cover_ext, blinker_pos_node_cover_ext], \n",
    "    [train_pos_labels_ext, grc_pos_labels_ext, heb_pos_labels_ext, blinker_pos_labels_ext])\n",
    "\n",
    "create_model(gnn_ds_train_pos_ext, gnn_ds_grc_pos_ext, gnn_ds_heb_pos_ext, gnn_ds_blinker_pos_ext, gnn_dataset_blinker_pos_bigbatch, tag_frequencies=True\n",
    "    , use_transformers=False, train_word_embedding=True, mask_language=False)\n",
    "\n",
    "# yoruba_postags = generate_target_lang_tags('yor-x-bible-2010', f\"posfeatTrue_transformerTrue_trainWETrue\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 3/250 [00:00<00:10, 23.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:10<00:00, 23.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, epoch: 0, total:7477 ACC: 0.8324194195532968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.set_device(4)\n",
    "model = torch.load('/mounts/work/ayyoob/models/gnn/checkpoint/postagging/pos_tagging_posfeatFalse_transformerFalse_trainWEFalse_maskLangTrue_20220209-201345.pickle', )\n",
    "torch.cuda.set_device(0)\n",
    "model.to(dev)\n",
    "epoch = 0\n",
    "test_data_loader = DataLoader(gnn_dataset_blinker_pos_onlyeng, batch_size=1, shuffle=False)\n",
    "test(epoch, test_data_loader, mask_language=False)\n",
    "yoruba_postags = generate_target_lang_tags('fin-x-bible-helfi', f\"posfeatTrue_transformerTrue_trainWETrue\", False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gold_frequencies_all' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-35f31c7e62aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#gold_frequencies_all = gold_frequencies\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mword_frequencies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgold_frequencies_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0msubjectword_indices\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mword_frequencies\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gold_frequencies_all' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "#normalized_gold_frequencies, gold_frequencies_all = get_words_tag_frequence(model, 2354770, len(postag_map), english_data_loader, from_gold_data=True)\n",
    "\n",
    "#gold_frequencies_all = gold_frequencies\n",
    "word_frequencies = torch.sum(gold_frequencies_all, dim=1)\n",
    "\n",
    "subjectword_indices =  word_frequencies > 0.1\n",
    "print(word_frequencies.shape)\n",
    "gold_frequencies = gold_frequencies_all[subjectword_indices, :]\n",
    "predicted_frequencies = tag_frequencies_english[subjectword_indices, :]\n",
    "wordtype_frequencies = word_frequencies[subjectword_indices]\n",
    "print(gold_frequencies.shape)\n",
    "\n",
    "_, gold_tags = torch.max(gold_frequencies, dim=1)\n",
    "_, predicted_tags = torch.max(predicted_frequencies, dim=1)\n",
    "\n",
    "sorted_wordtype_frequencies, sort_pattern = torch.sort(wordtype_frequencies, descending=True)\n",
    "\n",
    "sorted_gold_tags = gold_tags[sort_pattern]\n",
    "sorted_predicted_tags = predicted_tags[sort_pattern]\n",
    "quarter_size = int(sorted_gold_tags.size(0)/2.0)\n",
    "\n",
    "print('quarter size', quarter_size)\n",
    "print(\"general accuracy\", torch.sum(gold_tags == predicted_tags)/predicted_tags.size(0))\n",
    "print('first quarter accuracy', torch.sum(sorted_gold_tags[:quarter_size] == sorted_predicted_tags[:quarter_size])/quarter_size)\n",
    "print('last part accuracy', torch.sum(sorted_gold_tags[1*quarter_size:] == sorted_predicted_tags[1*quarter_size:])/sorted_predicted_tags[1*quarter_size:].size(0))\n",
    "\n",
    "print('total token count', torch.sum(wordtype_frequencies))\n",
    "print('first quarter words token count', torch.sum(word_frequencies[:quarter_size]))\n",
    "\n",
    "print('1st frequency', sorted_wordtype_frequencies[0])\n",
    "print('10st frequency', sorted_wordtype_frequencies[10])\n",
    "print('100st frequency', sorted_wordtype_frequencies[100])\n",
    "print('100st frequency', sorted_wordtype_frequencies[736])\n",
    "print('1000st frequency', sorted_wordtype_frequencies[1000])\n",
    "print('10000st frequency', sorted_wordtype_frequencies[10000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalized_tag_frequencies = torch.softmax(tag_frequencies_copy, dim=1)\n",
    "\n",
    "sm = torch.sum(tag_frequencies_copy, dim=1)\n",
    "normalized_tag_frequencies = (tag_frequencies_copy.transpose(1,0) / sm).transpose(1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global model, decoder\n",
    "#1/0\n",
    "\n",
    "decoder = None\n",
    "model = None\n",
    "\n",
    "gc.collect()\n",
    "with torch.no_grad():\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 1, 'out_dim': 20, 'global_normalize': False, 'name': 'editf', 'Active': True, 'n_classes': 83}\n",
      "{'type': 1, 'out_dim': 32, 'global_normalize': False, 'name': 'position', 'Active': True, 'n_classes': 150}\n",
      "{'type': 3, 'out_dim': 4, 'global_normalize': False, 'name': 'degree_centrality', 'Active': True}\n",
      "{'type': 3, 'out_dim': 4, 'global_normalize': False, 'name': 'closeness_centrality', 'Active': True}\n",
      "{'type': 3, 'out_dim': 4, 'global_normalize': False, 'name': 'betweenness_centrality', 'Active': True}\n",
      "{'type': 3, 'out_dim': 4, 'global_normalize': False, 'name': 'load_centrality', 'Active': True}\n",
      "{'type': 3, 'out_dim': 4, 'global_normalize': False, 'name': 'harmonic_centrality', 'Active': True}\n",
      "{'type': 1, 'out_dim': 32, 'global_normalize': False, 'name': 'greedy_modularity_community', 'Active': True, 'n_classes': 250}\n",
      "{'type': 1, 'out_dim': 32, 'global_normalize': False, 'name': 'label_propagation_community', 'Active': True, 'n_classes': 250}\n",
      "{'type': 6, 'out_dim': 100, 'global_normalize': False, 'name': 'word', 'Active': True}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#features = blinker_test_dataset.features[:]\n",
    "#features_edge = train_dataset.features_edge[:]\n",
    "from pprint import pprint\n",
    "#print('indim',in_dim)\n",
    "#features[-1].out_dim = 50\n",
    "for i in features:\n",
    "    #if i.type==3:\n",
    "    #    i.out_dim=4\n",
    "    print(vars(i))\n",
    "\n",
    "#sum(p.out_dim for p in features)\n",
    "#train_dataset.features.pop()\n",
    "#train_dataset.features[0] = afeatures.OneHotFeature(20, 83, 'editf')\n",
    "#train_dataset.features[1] = afeatures.OneHotFeature(32, 150, 'position')\n",
    "#train_dataset.features[2] = afeatures.FloatFeature(4, 'degree_centrality')\n",
    "#train_dataset.features[3] = afeatures.FloatFeature(4, 'closeness_centrality')\n",
    "#train_dataset.features[4] = afeatures.FloatFeature(4, 'betweenness_centrality')\n",
    "#train_dataset.features[5] = afeatures.FloatFeature(4, 'load_centrality')\n",
    "#train_dataset.features[6] = afeatures.FloatFeature(4, 'harmonic_centrality')\n",
    "#train_dataset.features[7] = afeatures.OneHotFeature(32, 250, 'greedy_modularity_community')\n",
    "##train_dataset.features.append(afeatures.MappingFeature(100, 'word'))\n",
    "#torch.save(train_dataset, \"/mounts/work/ayyoob/models/gnn/dataset_helfi_train_community_word.pickle\")\n",
    "#torch.save(train_dataset.features[-3], \"./features.tmp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_map = train_dataset.nodes_map\n",
    "bad_edition_files = []\n",
    "for edit in nodes_map:\n",
    "    bad_count = 0\n",
    "    for verse in nodes_map[edit]:\n",
    "        if len(nodes_map[edit][verse].keys()) < 2:\n",
    "            bad_count += 1\n",
    "        if bad_count > 1:\n",
    "            bad_edition_files.append(edit)\n",
    "            break\n",
    "print(bad_edition_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_japanese_nodes = set()\n",
    "nodes_map = train_dataset.nodes_map\n",
    "\n",
    "for bad_editionf in bad_edition_files:\n",
    "    for verse in nodes_map[bad_editionf]:\n",
    "        for item in nodes_map[bad_editionf][verse].items():\n",
    "            all_japanese_nodes.add(item[1])\n",
    "\n",
    "print(\" all japansese nodes: \", len(all_japanese_nodes))\n",
    "edge_index = train_dataset.edge_index.to('cpu')\n",
    "remaining_edges_index = []\n",
    "for i in tqdm(range(0, edge_index.shape[1], 2)):\n",
    "    if edge_index[0, i].item() not in all_japanese_nodes and edge_index[0, i+1].item() not in all_japanese_nodes:\n",
    "        remaining_edges_index.extend([i, i+1])\n",
    "\n",
    "print('original total edges count', edge_index.shape)\n",
    "print('remaining edge count', len(remaining_edges_index))\n",
    "train_dataset.edge_index = edge_index[:, remaining_edges_index]\n",
    "train_dataset.edge_index.shape\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aab640873abb67ad450730b814c8d7de015aa287a6fc3bae4b7154b533e57676"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('multalign_graph': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
